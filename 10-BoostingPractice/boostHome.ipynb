{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.setup_libs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) X-regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберемся со сложной бустинговой регулризацией. \n",
    "У нас есть реальные значения $y$ и некоторый неполный алгоритм $a$, который выдает по объектам значения $y^a$ ($y_i^{(t-1)}$ в теории)\n",
    "\n",
    "Мы создаем следующее дерево решений и оно как-то разбивает наши объекты на листья. (Разбение таргетов $Tree$ - содержит индексы объектов, а не сами объекты)\n",
    "\n",
    "Необходимо подсчитать функционал и новые оптимальные веса объектов.\n",
    "$$ Q = -\\frac{1}{2}\\sum_{j=1}^T \\frac{G_j^2}{H_j + \\lambda} + \\gamma T$$\n",
    "\n",
    "$$ w_j^* = -\\frac{G_j}{H_j + \\lambda}$$\n",
    "\n",
    " - $T$ — количество листьев в текущем дереве\n",
    " - $\\lambda, \\gamma$ — гиперпараметры\n",
    " - $G_j = \\sum_{i\\in I_j}g_i$ - сумма градиентов в одном листе по $g_i = \\partial_{\\hat{y}_i^a} \\mathcal{L}(y_i, \\hat{y}_i^a)$\n",
    " - $H_j = \\sum_{i\\in I_j}h_i$ - сумма гессианов в одном листе по $h_i = \\partial_{\\hat{y}_i^a}^2 \\mathcal{L}(y_i, \\hat{y}_i^a) $\n",
    " - $\\mathcal{L}(y_i, \\hat{y}_i^a) = (y_i - \\hat{y}_i^a)^2$\n",
    " - $\\hat{y}_i^a$ - значение **уже собранного** алгоритма \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xregul(y, y_prev, Tree):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = 0.5\n",
    "gamma = 0.5\n",
    "y = np.array([2, 4, 6, 8, 24, 26, 28, 34])\n",
    "y_prev = np.array([5, 5, 5, 5, 27, 27, 27, 27])\n",
    "Tree = np.array([np.array([0, 1, 2]), \n",
    "                 np.array([3]), \n",
    "                 np.array([4, 5, 6]), \n",
    "                 np.array([7])])\n",
    "\n",
    "\n",
    "Q, w = xregul(y, y_prev, Tree, gamma, lamb)\n",
    "    \n",
    "assert (Q - -50) < 0.1\n",
    "assert_almost_equal(w, np.array([-0.92, 2.4, -0.92, 5.6]), 2)\n",
    "\n",
    "#########################################\n",
    "lamb = 0.5\n",
    "gamma = 0.5\n",
    "y = np.array([2, 4, 6, 8, 24, 26, 28, 34])\n",
    "y_prev = np.array([3, 3, 7, 7, 26, 26, 26, 34])\n",
    "Tree = np.array([np.array([0, 1, 2]), \n",
    "                 np.array([3]), \n",
    "                 np.array([4, 5, 6]), \n",
    "                 np.array([7])])\n",
    "\n",
    "\n",
    "Q, w = xregul(y, y_prev, Tree, gamma, lamb)\n",
    "    \n",
    "assert (Q - 0.89) < 0.1\n",
    "assert_almost_equal(w, np.array([-0.3, 0.8, 0, 0]), 2)\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) X-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо найти наилучшие параметры для XGBRegression, обучить модель и вернуть ее. Данные брать [отсюда](https://yadi.sk/d/g-drGh61KLxRXQ).\n",
    "\n",
    "Сам гридсерч или нативное исследование необходимо делать вне функции обработки, чтобы не получить TL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xreg(X_train, y_train):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Financial Distress.csv')\n",
    "\n",
    "X = df.drop('Financial Distress', axis=1)\n",
    "y = df['Financial Distress']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
    "\n",
    "xgb_model = xreg(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "assert type(xgb_model) == xgb.sklearn.XGBRegressor\n",
    "assert MSE(y_pred, y_test) < 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) CatFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель классификации катбуста на предложенных данных и верните обученную модель. \n",
    "\n",
    "Воспользуйтесь встроенной обработкой категориальных признаков. Не забудьте обработать Nan значения.\n",
    "\n",
    "Скрытых тестов нет, только один [датасет](https://yadi.sk/i/tAkNkgHICbrHsA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catfeatures(df: pd.DataFrame):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.5 s, sys: 2.35 s, total: 33.9 s\n",
      "Wall time: 5.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('data/flight_delays_train.csv')\n",
    "df_train = df[:7000]\n",
    "model = catfeatures(df_train)\n",
    "\n",
    "\n",
    "assert type(model) == catboost.CatBoostClassifier\n",
    "\n",
    "df_test = pd.read_csv('data/flight_catfeature_test.csv')\n",
    "df_test = df_test.drop('Unnamed: 0', axis=1)\n",
    "X_test = df_test.drop('dep_delayed_15min',axis=1)\n",
    "y_test = df_test['dep_delayed_15min']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "assert accuracy_score(y_test, y_pred) > 0.80 \n",
    "assert accuracy_score(y_test, y_pred) < 0.87 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE(2) Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Стэкинг** - 3-ий способ комбинирования алгоритмов, кроме бэггинга и бустинга. Он не часто используется, но его идея крайне полезная: `обучение на мета-признаках`.\n",
    "\n",
    "1. Разобъем нашу обучающую выборку на 2 части: базовую и дополнительную.\n",
    "2. Возьмем $N$ базовых алгоритмов и обучим их на **базовой части** разбив на $N$ фолдов. (Разбили на $N$ частей и обучаем алгоритм на всех частях кроме одной, как на кросс-валидации)\n",
    "3. Каждым из обученных базовых алгоритмов предскажем значение для **дополнительной** части выборки.\n",
    "4. Соберем **мета-выборку**, состоящую из предсказаний базовых алгоритмов на **доп выборе**. Пример: пусть для объекта $x_i$ базовые алгоритмы выдали $(y_i^1 = 1, y_i^2 = 0, y_i^3 = 1)$. Тогда признаками объекта в **мета-выборке** будет вектор $1, 0, 1$.\n",
    "5. Обучим **мета-алгоритм** на **мета-выборке**. И получим готовую модель.\n",
    "6. Чтобы получить результат на тестовой, теперь нужно сделать предсказания базовыми алгоритмами, собрать **мета-выборку** и сделать предсказания на **мета-алгоритме**.\n",
    "\n",
    "Реализуйте стекинг классификацию на **деревьях решений**. Валидация проводится на [данном датасете](https://yadi.sk/d/QOAAohDJoDJVtQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "class Stacking():\n",
    "    def __init__(self, n_estimators=5, max_depth=5):\n",
    "        self.max_depth_ = max_depth\n",
    "        self.n_estimators_ = n_estimators\n",
    "        self.estimators_ = [DTC(max_depth=self.max_depth_) for _ in range(self.n_estimators_)]\n",
    "        self.meta_estimator_ = DTC(max_depth=self.max_depth_)\n",
    "        \n",
    "    def fit(self, X: np.array, y: np.array): \n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X_test) -> np.array:\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "df = pd.read_csv('data/forest_train.csv')\n",
    "\n",
    "X = df.drop(columns=['Cover_Type', 'Id']).reset_index(drop=True)\n",
    "y = df['Cover_Type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, train_size=0.3)\n",
    "\n",
    "model = Stacking(max_depth=10, n_estimators=3).fit(X_train, y_train)\n",
    "\n",
    "assert type(model.meta_estimator_) == sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred1 = model.estimators_[0].predict(X_test)\n",
    "y_pred2 = model.estimators_[1].predict(X_test)\n",
    "y_pred3 = model.estimators_[2].predict(X_test)\n",
    "\n",
    "assert accuracy_score(y_pred, y_test) > 0.67\n",
    "\n",
    "assert accuracy_score(y_pred1, y_test) < accuracy_score(y_pred, y_test)\n",
    "assert accuracy_score(y_pred2, y_test) < accuracy_score(y_pred, y_test)\n",
    "assert accuracy_score(y_pred3, y_test) < accuracy_score(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse",
   "language": "python",
   "name": "mlcourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
